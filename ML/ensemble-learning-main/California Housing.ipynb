{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predicting California housing prices using ensemble learning\n",
    "\n",
    "In this notebook we will use a Random Forest model to predict housing prices of houses in California.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì¶ Data provisioning\n",
    "\n",
    "The California housing dataset can be loaded using scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "dataset = fetch_california_housing()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first have a look into the format of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " 'frame': None,\n",
       " 'target_names': ['MedHouseVal'],\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 20640\\n\\n:Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n:Attribute Information:\\n    - MedInc        median income in block group\\n    - HouseAge      median house age in block group\\n    - AveRooms      average number of rooms per household\\n    - AveBedrms     average number of bedrooms per household\\n    - Population    block group population\\n    - AveOccup      average number of household members\\n    - Latitude      block group latitude\\n    - Longitude     block group longitude\\n\\n:Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 8 features (mentioned under feature names) and one continuous target variable MedHouseVal (median house value)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìÉ Sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.526, 3.585, 3.521, 3.413, 3.422, 2.697, 2.992, 2.414, 2.267,\n",
       "       2.611])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.526, 3.585, 3.521, 3.413, 3.422, 2.697, 2.992, 2.414, 2.267,\n",
       "       2.611])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è Preprocessing\n",
    "Since all features are already clean, we don't need to do any preprocessing in this case. Do take into account that longitude and latitude are related and mean something in real life (the location of the house). One could argue that these two features mean something in real life and we should treat them differently. However, since this is not the focus of this notebook we will treat them as separate features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü™ì Splitting into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are in total 20640 observations, of which 15480 are now in the train set, and 5160 in the test set.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=21\n",
    ")\n",
    "print(\"There are in total\", len(X), \"observations, of which\", len(X_train), \"are now in the train set, and\", len(X_test), \"in the test set.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß¨ Modelling\n",
    "\n",
    "### Decision Tree\n",
    "\n",
    "Let's start by applying a Decision Tree as we have seen before. Since our target variable is continuous, we do not have a classification problem but a regression problem. This means we will have to use the DecisionTreeRegressor from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6008678894603974"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree = DecisionTreeRegressor(random_state=21, max_depth=25)\n",
    "tree.fit(X_train, y_train)\n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-squared value is about 0.6. Although this shows that our model can predict something, it is not exactly mind-blowing.\n",
    "\n",
    "This is not the end of the story though. Let's try doing the same with max_depth=10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6885848151723583"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree = DecisionTreeRegressor(random_state=21, max_depth=10)\n",
    "tree.fit(X_train, y_train)\n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-squared just went up almost by 0.09! How would you explain this?\n",
    "\n",
    "The next question is what would be the best value for the parameter max_depth. In the exercise we will find this by applying grid search."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Now let's see whether we can improve our model by applying a Random Forest. This is an example of a bagging ensemble algorithm, since we construct trees based on different (random) samples of the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8050417860881305"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "random_forest = RandomForestRegressor(n_estimators = 50, max_depth=25, n_jobs=-1)\n",
    "random_forest.fit(X_train, y_train)\n",
    "random_forest.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some randomness in the model, so we find different accuracies every time we run it. We tend to find R-squared values of around 0.8 which is quite an improvement with using a single decision tree! Let's see whether we can do better by optimizing the n_estimators parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8093268104631148"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "random_forest = RandomForestRegressor(n_estimators = 100, max_depth=25, n_jobs=-1)\n",
    "random_forest.fit(X_train, y_train)\n",
    "random_forest.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our result got a little bit better, but we would have to validate this using cross-validation to make proper conclusions. We will do so in the exercise, while finding a good value for the parameter n_estimators."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance\n",
    "\n",
    "An important benefit of using random forests is that we can get some idea what features were important when determining the target variables (median house price)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "forest_importances = pd.Series(random_forest.feature_importances_, index=dataset.feature_names)\n",
    "\n",
    "standard_deviation = np.std([tree.feature_importances_ for tree in random_forest.estimators_], axis=0)\n",
    "\n",
    "plt.figure()\n",
    "forest_importances.plot.bar(yerr=standard_deviation)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the MedInc (median income) seems to be the most important variable in predicting the median house price. The second most important feature is AveOccup (average occupation), then the latitude and longitude. Does this match your expectations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7814795740178104"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "\n",
    "\n",
    "# Now you can use these boosted estimators in your ensemble\n",
    "estimators = [ \n",
    "    ('ridge', RidgeCV()),  \n",
    "    ('svr', LinearSVR(dual=\"auto\", random_state=21)), \n",
    "    ('dtr', DecisionTreeRegressor(random_state=21, max_depth=15))\n",
    "]\n",
    "\n",
    "reg = StackingRegressor( estimators=estimators, final_estimator=RandomForestRegressor(n_estimators=10, random_state=21, max_depth=12) )\n",
    "\n",
    "reg.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8113846777187396"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "\n",
    "# Define base estimators\n",
    "ridge = RidgeCV()\n",
    "svr = LinearSVR(dual=\"auto\", random_state=21)\n",
    "dtr = DecisionTreeRegressor(random_state=21, max_depth=15)\n",
    "\n",
    "# Apply AdaBoost to each base estimator\n",
    "ridge_boosted = AdaBoostRegressor(estimator=ridge, random_state=0, n_estimators=100)\n",
    "svr_boosted = AdaBoostRegressor(estimator=svr, random_state=0, n_estimators=100)\n",
    "dtr_boosted = AdaBoostRegressor(estimator=dtr, random_state=0, n_estimators=100)\n",
    "\n",
    "# Now you can use these boosted estimators in your ensemble\n",
    "estimators = [ \n",
    "    ('ridge_boosted', ridge_boosted),  \n",
    "    ('svr_boosted', svr_boosted), \n",
    "    ('dtr_boosted', dtr_boosted)\n",
    "]\n",
    "\n",
    "reg = StackingRegressor( estimators=estimators, final_estimator=RandomForestRegressor(n_estimators=10, random_state=21, max_depth=12) )\n",
    "\n",
    "reg.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.143508</td>\n",
       "      <td>0.011802</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 10, 'random_state': 8}</td>\n",
       "      <td>0.655621</td>\n",
       "      <td>0.691029</td>\n",
       "      <td>0.685845</td>\n",
       "      <td>0.673280</td>\n",
       "      <td>0.700821</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.157496</td>\n",
       "      <td>0.017068</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 10, 'random_state': 20}</td>\n",
       "      <td>0.654652</td>\n",
       "      <td>0.680625</td>\n",
       "      <td>0.683388</td>\n",
       "      <td>0.676777</td>\n",
       "      <td>0.702934</td>\n",
       "      <td>0.679675</td>\n",
       "      <td>0.015429</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.117253</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>{'max_depth': 8, 'random_state': 27}</td>\n",
       "      <td>0.681218</td>\n",
       "      <td>0.693028</td>\n",
       "      <td>0.663992</td>\n",
       "      <td>0.671748</td>\n",
       "      <td>0.688248</td>\n",
       "      <td>0.679647</td>\n",
       "      <td>0.010611</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.118346</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>{'max_depth': 8, 'random_state': 47}</td>\n",
       "      <td>0.680727</td>\n",
       "      <td>0.694025</td>\n",
       "      <td>0.664318</td>\n",
       "      <td>0.667236</td>\n",
       "      <td>0.690217</td>\n",
       "      <td>0.679305</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.137959</td>\n",
       "      <td>0.003827</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>{'max_depth': 10, 'random_state': 14}</td>\n",
       "      <td>0.655579</td>\n",
       "      <td>0.685318</td>\n",
       "      <td>0.681351</td>\n",
       "      <td>0.677908</td>\n",
       "      <td>0.695495</td>\n",
       "      <td>0.679130</td>\n",
       "      <td>0.013170</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>0.252296</td>\n",
       "      <td>0.021998</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.003036</td>\n",
       "      <td>26</td>\n",
       "      <td>46</td>\n",
       "      <td>{'max_depth': 26, 'random_state': 46}</td>\n",
       "      <td>0.560923</td>\n",
       "      <td>0.572897</td>\n",
       "      <td>0.590023</td>\n",
       "      <td>0.594332</td>\n",
       "      <td>0.596673</td>\n",
       "      <td>0.582970</td>\n",
       "      <td>0.013814</td>\n",
       "      <td>2158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>0.252808</td>\n",
       "      <td>0.018893</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_depth': 30, 'random_state': 12}</td>\n",
       "      <td>0.556692</td>\n",
       "      <td>0.566323</td>\n",
       "      <td>0.585792</td>\n",
       "      <td>0.589961</td>\n",
       "      <td>0.614473</td>\n",
       "      <td>0.582648</td>\n",
       "      <td>0.020082</td>\n",
       "      <td>2159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>0.262373</td>\n",
       "      <td>0.016475</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>0.003016</td>\n",
       "      <td>27</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_depth': 27, 'random_state': 42}</td>\n",
       "      <td>0.548495</td>\n",
       "      <td>0.581016</td>\n",
       "      <td>0.584821</td>\n",
       "      <td>0.585439</td>\n",
       "      <td>0.611149</td>\n",
       "      <td>0.582184</td>\n",
       "      <td>0.019964</td>\n",
       "      <td>2160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>0.240246</td>\n",
       "      <td>0.004891</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>26</td>\n",
       "      <td>37</td>\n",
       "      <td>{'max_depth': 26, 'random_state': 37}</td>\n",
       "      <td>0.559927</td>\n",
       "      <td>0.564383</td>\n",
       "      <td>0.591397</td>\n",
       "      <td>0.585016</td>\n",
       "      <td>0.609216</td>\n",
       "      <td>0.581988</td>\n",
       "      <td>0.018087</td>\n",
       "      <td>2161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>0.236245</td>\n",
       "      <td>0.010448</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 23, 'random_state': 10}</td>\n",
       "      <td>0.549420</td>\n",
       "      <td>0.559565</td>\n",
       "      <td>0.593497</td>\n",
       "      <td>0.587115</td>\n",
       "      <td>0.605828</td>\n",
       "      <td>0.579085</td>\n",
       "      <td>0.021206</td>\n",
       "      <td>2162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2162 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "239        0.143508      0.011802         0.001084        0.001467   \n",
       "251        0.157496      0.017068         0.001498        0.002751   \n",
       "164        0.117253      0.004696         0.001952        0.001858   \n",
       "184        0.118346      0.004283         0.001450        0.001776   \n",
       "245        0.137959      0.003827         0.002007        0.004014   \n",
       "...             ...           ...              ...             ...   \n",
       "1029       0.252296      0.021998         0.002924        0.003036   \n",
       "1183       0.252808      0.018893         0.001971        0.001040   \n",
       "1072       0.262373      0.016475         0.004110        0.003016   \n",
       "1020       0.240246      0.004891         0.001621        0.001006   \n",
       "852        0.236245      0.010448         0.001654        0.000838   \n",
       "\n",
       "     param_max_depth param_random_state  \\\n",
       "239               10                  8   \n",
       "251               10                 20   \n",
       "164                8                 27   \n",
       "184                8                 47   \n",
       "245               10                 14   \n",
       "...              ...                ...   \n",
       "1029              26                 46   \n",
       "1183              30                 12   \n",
       "1072              27                 42   \n",
       "1020              26                 37   \n",
       "852               23                 10   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "239    {'max_depth': 10, 'random_state': 8}           0.655621   \n",
       "251   {'max_depth': 10, 'random_state': 20}           0.654652   \n",
       "164    {'max_depth': 8, 'random_state': 27}           0.681218   \n",
       "184    {'max_depth': 8, 'random_state': 47}           0.680727   \n",
       "245   {'max_depth': 10, 'random_state': 14}           0.655579   \n",
       "...                                     ...                ...   \n",
       "1029  {'max_depth': 26, 'random_state': 46}           0.560923   \n",
       "1183  {'max_depth': 30, 'random_state': 12}           0.556692   \n",
       "1072  {'max_depth': 27, 'random_state': 42}           0.548495   \n",
       "1020  {'max_depth': 26, 'random_state': 37}           0.559927   \n",
       "852   {'max_depth': 23, 'random_state': 10}           0.549420   \n",
       "\n",
       "      split1_test_score  split2_test_score  split3_test_score  \\\n",
       "239            0.691029           0.685845           0.673280   \n",
       "251            0.680625           0.683388           0.676777   \n",
       "164            0.693028           0.663992           0.671748   \n",
       "184            0.694025           0.664318           0.667236   \n",
       "245            0.685318           0.681351           0.677908   \n",
       "...                 ...                ...                ...   \n",
       "1029           0.572897           0.590023           0.594332   \n",
       "1183           0.566323           0.585792           0.589961   \n",
       "1072           0.581016           0.584821           0.585439   \n",
       "1020           0.564383           0.591397           0.585016   \n",
       "852            0.559565           0.593497           0.587115   \n",
       "\n",
       "      split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "239            0.700821         0.681319        0.015621                1  \n",
       "251            0.702934         0.679675        0.015429                2  \n",
       "164            0.688248         0.679647        0.010611                3  \n",
       "184            0.690217         0.679305        0.011900                4  \n",
       "245            0.695495         0.679130        0.013170                5  \n",
       "...                 ...              ...             ...              ...  \n",
       "1029           0.596673         0.582970        0.013814             2158  \n",
       "1183           0.614473         0.582648        0.020082             2159  \n",
       "1072           0.611149         0.582184        0.019964             2160  \n",
       "1020           0.609216         0.581988        0.018087             2161  \n",
       "852            0.605828         0.579085        0.021206             2162  \n",
       "\n",
       "[2162 rows x 15 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "parameters = {'random_state':list(range(4, 51)), 'max_depth':list(range(5, 51))}\n",
    "\n",
    "dtr = DecisionTreeRegressor()\n",
    "clf = GridSearchCV(dtr, parameters, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "df.sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_n_jobs</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.168148</td>\n",
       "      <td>0.019381</td>\n",
       "      <td>0.026524</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>34</td>\n",
       "      <td>{'bootstrap': True, 'n_jobs': -1, 'random_stat...</td>\n",
       "      <td>0.788279</td>\n",
       "      <td>0.782279</td>\n",
       "      <td>0.766094</td>\n",
       "      <td>0.775729</td>\n",
       "      <td>0.794858</td>\n",
       "      <td>0.781448</td>\n",
       "      <td>0.009956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.167585</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>0.028639</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>37</td>\n",
       "      <td>{'bootstrap': True, 'n_jobs': -1, 'random_stat...</td>\n",
       "      <td>0.783456</td>\n",
       "      <td>0.772154</td>\n",
       "      <td>0.782001</td>\n",
       "      <td>0.775796</td>\n",
       "      <td>0.792305</td>\n",
       "      <td>0.781142</td>\n",
       "      <td>0.006929</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.165366</td>\n",
       "      <td>0.006486</td>\n",
       "      <td>0.024383</td>\n",
       "      <td>0.004326</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>39</td>\n",
       "      <td>{'bootstrap': True, 'n_jobs': -1, 'random_stat...</td>\n",
       "      <td>0.785870</td>\n",
       "      <td>0.780831</td>\n",
       "      <td>0.772264</td>\n",
       "      <td>0.777190</td>\n",
       "      <td>0.785631</td>\n",
       "      <td>0.780357</td>\n",
       "      <td>0.005176</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.158126</td>\n",
       "      <td>0.006887</td>\n",
       "      <td>0.024138</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'bootstrap': True, 'n_jobs': -1, 'random_stat...</td>\n",
       "      <td>0.789085</td>\n",
       "      <td>0.775420</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.772015</td>\n",
       "      <td>0.791815</td>\n",
       "      <td>0.780283</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.158998</td>\n",
       "      <td>0.009240</td>\n",
       "      <td>0.023603</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'bootstrap': True, 'n_jobs': -1, 'random_stat...</td>\n",
       "      <td>0.785337</td>\n",
       "      <td>0.776581</td>\n",
       "      <td>0.772954</td>\n",
       "      <td>0.768331</td>\n",
       "      <td>0.796241</td>\n",
       "      <td>0.779889</td>\n",
       "      <td>0.009897</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.242168</td>\n",
       "      <td>0.011619</td>\n",
       "      <td>0.145684</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>49</td>\n",
       "      <td>{'bootstrap': False, 'n_jobs': -1, 'random_sta...</td>\n",
       "      <td>0.590925</td>\n",
       "      <td>0.600492</td>\n",
       "      <td>0.616969</td>\n",
       "      <td>0.624127</td>\n",
       "      <td>0.637991</td>\n",
       "      <td>0.614101</td>\n",
       "      <td>0.016744</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.248534</td>\n",
       "      <td>0.013308</td>\n",
       "      <td>0.144690</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>37</td>\n",
       "      <td>{'bootstrap': False, 'n_jobs': -1, 'random_sta...</td>\n",
       "      <td>0.590028</td>\n",
       "      <td>0.599280</td>\n",
       "      <td>0.619804</td>\n",
       "      <td>0.621742</td>\n",
       "      <td>0.638388</td>\n",
       "      <td>0.613848</td>\n",
       "      <td>0.017203</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.254132</td>\n",
       "      <td>0.009830</td>\n",
       "      <td>0.148759</td>\n",
       "      <td>0.004636</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'bootstrap': False, 'n_jobs': -1, 'random_sta...</td>\n",
       "      <td>0.589390</td>\n",
       "      <td>0.598321</td>\n",
       "      <td>0.622245</td>\n",
       "      <td>0.623778</td>\n",
       "      <td>0.634931</td>\n",
       "      <td>0.613733</td>\n",
       "      <td>0.017046</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.252508</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.149753</td>\n",
       "      <td>0.005934</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>23</td>\n",
       "      <td>{'bootstrap': False, 'n_jobs': -1, 'random_sta...</td>\n",
       "      <td>0.592059</td>\n",
       "      <td>0.598467</td>\n",
       "      <td>0.615734</td>\n",
       "      <td>0.619774</td>\n",
       "      <td>0.641040</td>\n",
       "      <td>0.613415</td>\n",
       "      <td>0.017254</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.256599</td>\n",
       "      <td>0.005931</td>\n",
       "      <td>0.147919</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>41</td>\n",
       "      <td>{'bootstrap': False, 'n_jobs': -1, 'random_sta...</td>\n",
       "      <td>0.590042</td>\n",
       "      <td>0.597911</td>\n",
       "      <td>0.615343</td>\n",
       "      <td>0.625260</td>\n",
       "      <td>0.631711</td>\n",
       "      <td>0.612053</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "14       0.168148      0.019381         0.026524        0.004920   \n",
       "17       0.167585      0.003541         0.028639        0.005333   \n",
       "19       0.165366      0.006486         0.024383        0.004326   \n",
       "30       0.158126      0.006887         0.024138        0.004255   \n",
       "22       0.158998      0.009240         0.023603        0.004197   \n",
       "..            ...           ...              ...             ...   \n",
       "60       0.242168      0.011619         0.145684        0.001267   \n",
       "48       0.248534      0.013308         0.144690        0.001020   \n",
       "53       0.254132      0.009830         0.148759        0.004636   \n",
       "34       0.252508      0.004007         0.149753        0.005934   \n",
       "52       0.256599      0.005931         0.147919        0.006381   \n",
       "\n",
       "   param_bootstrap param_n_jobs param_random_state  \\\n",
       "14            True           -1                 34   \n",
       "17            True           -1                 37   \n",
       "19            True           -1                 39   \n",
       "30            True           -1                 50   \n",
       "22            True           -1                 42   \n",
       "..             ...          ...                ...   \n",
       "60           False           -1                 49   \n",
       "48           False           -1                 37   \n",
       "53           False           -1                 42   \n",
       "34           False           -1                 23   \n",
       "52           False           -1                 41   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "14  {'bootstrap': True, 'n_jobs': -1, 'random_stat...           0.788279   \n",
       "17  {'bootstrap': True, 'n_jobs': -1, 'random_stat...           0.783456   \n",
       "19  {'bootstrap': True, 'n_jobs': -1, 'random_stat...           0.785870   \n",
       "30  {'bootstrap': True, 'n_jobs': -1, 'random_stat...           0.789085   \n",
       "22  {'bootstrap': True, 'n_jobs': -1, 'random_stat...           0.785337   \n",
       "..                                                ...                ...   \n",
       "60  {'bootstrap': False, 'n_jobs': -1, 'random_sta...           0.590925   \n",
       "48  {'bootstrap': False, 'n_jobs': -1, 'random_sta...           0.590028   \n",
       "53  {'bootstrap': False, 'n_jobs': -1, 'random_sta...           0.589390   \n",
       "34  {'bootstrap': False, 'n_jobs': -1, 'random_sta...           0.592059   \n",
       "52  {'bootstrap': False, 'n_jobs': -1, 'random_sta...           0.590042   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "14           0.782279           0.766094           0.775729   \n",
       "17           0.772154           0.782001           0.775796   \n",
       "19           0.780831           0.772264           0.777190   \n",
       "30           0.775420           0.773077           0.772015   \n",
       "22           0.776581           0.772954           0.768331   \n",
       "..                ...                ...                ...   \n",
       "60           0.600492           0.616969           0.624127   \n",
       "48           0.599280           0.619804           0.621742   \n",
       "53           0.598321           0.622245           0.623778   \n",
       "34           0.598467           0.615734           0.619774   \n",
       "52           0.597911           0.615343           0.625260   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "14           0.794858         0.781448        0.009956                1  \n",
       "17           0.792305         0.781142        0.006929                2  \n",
       "19           0.785631         0.780357        0.005176                3  \n",
       "30           0.791815         0.780283        0.008419                4  \n",
       "22           0.796241         0.779889        0.009897                5  \n",
       "..                ...              ...             ...              ...  \n",
       "60           0.637991         0.614101        0.016744               58  \n",
       "48           0.638388         0.613848        0.017203               59  \n",
       "53           0.634931         0.613733        0.017046               60  \n",
       "34           0.641040         0.613415        0.017254               61  \n",
       "52           0.631711         0.612053        0.015850               62  \n",
       "\n",
       "[62 rows x 16 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'bootstrap':[True, False], 'random_state':list(range(20, 51)), 'n_jobs':[-1]}\n",
    "\n",
    "dtr = BaggingRegressor()\n",
    "clf = GridSearchCV(dtr, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "df.sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and here i use baggingregression to see what that does. and it isn't better or worse than the rest so. don't know how it will work in other datasets though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7953496000281135"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BaggingRegressor()\n",
    "\n",
    "model.fit(X_train, y_train).score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d90f0983be1ef93a393dd26ac4b5f2b3e279b7688d93e5762afc622c8c2430b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
